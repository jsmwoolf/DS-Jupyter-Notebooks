{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Ah, baby names. When it’s time, we want to provide the best name for our children. On oc- cassion, we can determine the ethnicity of a person simply by their name. This can also lead to discrimination, especially when applying for jobs.\n",
    "\n",
    "Today, resumes submitted online goes through a system to determine how good of a candidate you are. __Now, how accurate can a computer determine someone’s ethnicity?__\n",
    "\n",
    "Note that in this dataset, our scope is with first names within New York City."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving and reorganizing our data\n",
    "\n",
    "The first step in this analysis is to retrieve the data and reorganize it using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13962"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "         \n",
    "theData = pd.read_csv(\n",
    "            \"Most_Popular_Baby_Names_by_Sex_and_Mother_s_Ethnic_Group__New_York_City.csv\"\n",
    "            )\n",
    "len(theData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRTH_YR</th>\n",
       "      <th>GNDR</th>\n",
       "      <th>ETHCTY</th>\n",
       "      <th>NM</th>\n",
       "      <th>CNT</th>\n",
       "      <th>RNK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>GERALDINE</td>\n",
       "      <td>13</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>GIA</td>\n",
       "      <td>21</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>GIANNA</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>GISELLE</td>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>GRACE</td>\n",
       "      <td>36</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BRTH_YR    GNDR    ETHCTY         NM  CNT  RNK\n",
       "0     2011  FEMALE  HISPANIC  GERALDINE   13   75\n",
       "1     2011  FEMALE  HISPANIC        GIA   21   67\n",
       "2     2011  FEMALE  HISPANIC     GIANNA   49   42\n",
       "3     2011  FEMALE  HISPANIC    GISELLE   38   51\n",
       "4     2011  FEMALE  HISPANIC      GRACE   36   53"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A glimpse on the table \n",
    "theData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform this analysis, we will use two variables to train our model: \n",
    "\n",
    "- The gender \n",
    "- The name \n",
    "\n",
    "The output will be the ethnicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling the Data\n",
    "\n",
    "Upon inspecting the data, we notice a few things we need to change before we begin training our model.\n",
    "\n",
    "First, we have a count column that’s associated with the occurrance of each row. We should unroll every instance of the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRTH_YR</th>\n",
       "      <th>ETHCTY</th>\n",
       "      <th>GNDR</th>\n",
       "      <th>NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>GERALDINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>GERALDINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>GERALDINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>GERALDINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>HISPANIC</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>GERALDINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BRTH_YR    ETHCTY    GNDR         NM\n",
       "0     2011  HISPANIC  FEMALE  GERALDINE\n",
       "1     2011  HISPANIC  FEMALE  GERALDINE\n",
       "2     2011  HISPANIC  FEMALE  GERALDINE\n",
       "3     2011  HISPANIC  FEMALE  GERALDINE\n",
       "4     2011  HISPANIC  FEMALE  GERALDINE"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData = {column:[] for column in list(theData.columns)[:4]}\n",
    "\n",
    "for index, row in theData.iterrows():\n",
    "    for count in range(row['CNT']):\n",
    "        newData[\"BRTH_YR\"].append(row[\"BRTH_YR\"])\n",
    "        newData[\"GNDR\"].append(row[\"GNDR\"])\n",
    "        newData[\"ETHCTY\"].append(row[\"ETHCTY\"])\n",
    "        newData[\"NM\"].append(row[\"NM\"])\n",
    "theData = pd.DataFrame(newData)\n",
    "theData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, there appears to be a redundancy on ethnicity types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HISPANIC                      167237\n",
       "WHITE NON HISPANIC            154067\n",
       "BLACK NON HISPANIC             62265\n",
       "ASIAN AND PACIFIC ISLANDER     51379\n",
       "WHITE NON HISP                 26675\n",
       "ASIAN AND PACI                 10300\n",
       "BLACK NON HISP                 10208\n",
       "Name: ETHCTY, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicCount = theData['ETHCTY'].value_counts()\n",
    "ethnicCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the last three columns are meant to be part of another pre-existing category. We’re going to need to correct this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE NON HISPANIC            180742\n",
       "HISPANIC                      167237\n",
       "BLACK NON HISPANIC             72473\n",
       "ASIAN AND PACIFIC ISLANDER     61679\n",
       "Name: ETHCTY, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theData.loc[theData[\"ETHCTY\"] == \"WHITE NON HISP\", \"ETHCTY\"]= \"WHITE NON HISPANIC\"\n",
    "theData.loc[theData[\"ETHCTY\"] == \"ASIAN AND PACI\", \"ETHCTY\"] = \"ASIAN AND PACIFIC ISLANDER\"\n",
    "theData.loc[theData[\"ETHCTY\"] == \"BLACK NON HISP\", \"ETHCTY\"] = \"BLACK NON HISPANIC\"\n",
    "\n",
    "ethnicCount = theData['ETHCTY'].value_counts()\n",
    "ethnicCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for names, the data contains a mix of upper and lower case letters, so we’ll convert all names to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is for converting all names to uppercase \n",
    "theData['NM'] = theData['NM'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "To determine how accurate the claim actually is, we’re going to use Naive Bayes. Navie Bayes assumes that all evidence is independent from each other.\n",
    "\n",
    "We’ll determine the probability as follows:\n",
    "\n",
    "$$ P(ethnicity|gender, name) = P(ethnicity) ∗ P(gender|ethnicity) ∗ P(name|ethnicity)$$ \n",
    "\n",
    "But first, we’ll need to calculate all of the probabilities defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIAN AND PACIFIC ISLANDER</th>\n",
       "      <th>BLACK NON HISPANIC</th>\n",
       "      <th>HISPANIC</th>\n",
       "      <th>WHITE NON HISPANIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12793</td>\n",
       "      <td>0.150318</td>\n",
       "      <td>0.34687</td>\n",
       "      <td>0.374882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASIAN AND PACIFIC ISLANDER  BLACK NON HISPANIC  HISPANIC  \\\n",
       "0                     0.12793            0.150318   0.34687   \n",
       "\n",
       "   WHITE NON HISPANIC  \n",
       "0            0.374882  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the ethnicity table\n",
    "ethnicProb = {\n",
    "    ethnicCount.keys()[i]:ethnicCount[i]/len(theData) \n",
    "        for i in range(ethnicCount.nunique())\n",
    "    }\n",
    "ethnicTable = pd.DataFrame(ethnicProb,index=[0])\n",
    "ethnicTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>MALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WHITE NON HISPANIC</th>\n",
       "      <td>0.457608</td>\n",
       "      <td>0.542392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC</th>\n",
       "      <td>0.423076</td>\n",
       "      <td>0.576924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK NON HISPANIC</th>\n",
       "      <td>0.419467</td>\n",
       "      <td>0.580533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASIAN AND PACIFIC ISLANDER</th>\n",
       "      <td>0.425104</td>\n",
       "      <td>0.574896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              FEMALE      MALE\n",
       "WHITE NON HISPANIC          0.457608  0.542392\n",
       "HISPANIC                    0.423076  0.576924\n",
       "BLACK NON HISPANIC          0.419467  0.580533\n",
       "ASIAN AND PACIFIC ISLANDER  0.425104  0.574896"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the gender given ethnicity table \n",
    "genderProb = []\n",
    "for ethnicity in ethnicCount.keys():\n",
    "    ethData = theData[theData['ETHCTY'] == ethnicity]\n",
    "    genderCount = ethData['GNDR'].value_counts()\n",
    "    temp = {genderCount.keys()[i]:genderCount[i]/len(ethData)\n",
    "                for i in range(genderCount.nunique())}\n",
    "    genderProb.append(temp)\n",
    "genderTable = pd.DataFrame(genderProb,index=ethnicCount.keys())\n",
    "genderTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAHIL</th>\n",
       "      <th>AALIYAH</th>\n",
       "      <th>AARAV</th>\n",
       "      <th>AARON</th>\n",
       "      <th>AARYA</th>\n",
       "      <th>AAYAN</th>\n",
       "      <th>ABBY</th>\n",
       "      <th>ABDIEL</th>\n",
       "      <th>ABDOUL</th>\n",
       "      <th>ABDOULAYE</th>\n",
       "      <th>...</th>\n",
       "      <th>ZELDA</th>\n",
       "      <th>ZENDAYA</th>\n",
       "      <th>ZEV</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZISSY</th>\n",
       "      <th>ZOE</th>\n",
       "      <th>ZOEY</th>\n",
       "      <th>ZOYA</th>\n",
       "      <th>ZURI</th>\n",
       "      <th>ZYAIRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WHITE NON HISPANIC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK NON HISPANIC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.000773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASIAN AND PACIFIC ISLANDER</th>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1629 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               AAHIL   AALIYAH     AARAV     AARON     AARYA  \\\n",
       "WHITE NON HISPANIC          0.000000  0.000000  0.000000  0.002954  0.000000   \n",
       "HISPANIC                    0.000000  0.002577  0.000000  0.004694  0.000000   \n",
       "BLACK NON HISPANIC          0.000000  0.006499  0.000000  0.004705  0.000000   \n",
       "ASIAN AND PACIFIC ISLANDER  0.000227  0.000000  0.001411  0.006469  0.000162   \n",
       "\n",
       "                               AAYAN      ABBY    ABDIEL    ABDOUL  ABDOULAYE  \\\n",
       "WHITE NON HISPANIC          0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "HISPANIC                    0.000000  0.000239  0.000353  0.000000   0.000000   \n",
       "BLACK NON HISPANIC          0.000000  0.000000  0.000000  0.001173   0.001366   \n",
       "ASIAN AND PACIFIC ISLANDER  0.000584  0.000859  0.000000  0.000000   0.000000   \n",
       "\n",
       "                              ...        ZELDA   ZENDAYA       ZEV      ZION  \\\n",
       "WHITE NON HISPANIC            ...     0.000127  0.000000  0.001848  0.000000   \n",
       "HISPANIC                      ...     0.000000  0.000000  0.000000  0.000478   \n",
       "BLACK NON HISPANIC            ...     0.000000  0.000179  0.000000  0.003808   \n",
       "ASIAN AND PACIFIC ISLANDER    ...     0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                               ZISSY       ZOE      ZOEY      ZOYA    ZURI  \\\n",
       "WHITE NON HISPANIC          0.000979  0.003303  0.000880  0.000000  0.0000   \n",
       "HISPANIC                    0.000000  0.003008  0.001268  0.000000  0.0000   \n",
       "BLACK NON HISPANIC          0.000000  0.003808  0.002842  0.000000  0.0012   \n",
       "ASIAN AND PACIFIC ISLANDER  0.000000  0.003486  0.001102  0.000259  0.0000   \n",
       "\n",
       "                              ZYAIRE  \n",
       "WHITE NON HISPANIC          0.000000  \n",
       "HISPANIC                    0.000000  \n",
       "BLACK NON HISPANIC          0.000773  \n",
       "ASIAN AND PACIFIC ISLANDER  0.000000  \n",
       "\n",
       "[4 rows x 1629 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the name given ethnicity table\n",
    "nameProb = [{\n",
    "    name:0 for name in theData['NM'].value_counts().keys()}\n",
    "        for j in theData['ETHCTY'].value_counts()] \n",
    "for i in range(theData['ETHCTY'].nunique()):\n",
    "    ethnicity = ethnicCount.keys()[i]\n",
    "    ethData = theData[theData['ETHCTY'] == ethnicity]\n",
    "    nameCount = ethData['NM'].value_counts()\n",
    "    for j in range(ethData['NM'].nunique()):\n",
    "        name = nameCount.keys()[j]\n",
    "        nameProb[i][name] = nameCount[j]/len(ethData)\n",
    "nameTable = pd.DataFrame(nameProb,index=ethnicCount.keys())\n",
    "nameTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting\n",
    "\n",
    "Now, we’re going to predict the ethnicity given the data. We’ll be using a function to calculate the predicted ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(gender, name):\n",
    "    bestRes = 0\n",
    "    theName = ''\n",
    "    for ethnicity in ethnicTable:\n",
    "        res = float(ethnicTable[ethnicity]) * \\\n",
    "              float(genderTable[gender][ethnicity]) * \\\n",
    "              float(nameTable[name][ethnicity])\n",
    "        if bestRes <= res:\n",
    "            bestRes = res\n",
    "            theName = ethnicity\n",
    "    return theName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6429061811001574\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for index, row in theData.iterrows():\n",
    "    if predict(row['GNDR'],row['NM']) == row['ETHCTY']:\n",
    "        acc += 1\n",
    "print(acc / len(theData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, Navie Bayes can correctly determines a person’s ethnicity 64% of the time. If we were to assume independence, then the model is really poor at determining ethnicitiy.\n",
    "\n",
    "Now, how much better would the model perform if we considered dependence for the variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with dependence\n",
    "\n",
    "We’ll determine the new probability as follows:\n",
    "\n",
    "$$P(ethnicity|gender, name) = P(ethnicity) ∗ P(gender|ethnicity) ∗ P(name|gender, ethnicity)$$ \n",
    "\n",
    "We only need to calculate the name tables for each gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the name given ethnicity table \n",
    "nameProb = {}\n",
    "for gender in genderTable:\n",
    "    tempData = theData[theData['GNDR'] == gender]\n",
    "    nameProbGender = [{name:0.0 for name in tempData['NM'].value_counts().keys()}\n",
    "                        for j in tempData['ETHCTY'].value_counts()]\n",
    "    nameProbGender = pd.DataFrame(nameProbGender,index=ethnicCount.keys())\n",
    "    for ethnicity in tempData['ETHCTY'].value_counts().keys():\n",
    "        ethData = tempData[tempData['ETHCTY'] == ethnicity]\n",
    "        nameCount = ethData['NM'].value_counts()\n",
    "        for j in range(ethData['NM'].nunique()):\n",
    "            name = nameCount.keys()[j]\n",
    "            nameProbGender[name][ethnicity] = nameCount[j]/len(ethData)\n",
    "            nameProbGender[name][ethnicity]\n",
    "    nameProb[gender] = nameProbGender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are relying on dependency, we’ll need a new prediction algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictDep(gender, name):\n",
    "    bestRes = 0\n",
    "    theName = ''\n",
    "    for ethnicity in ethnicTable:\n",
    "        res = float(ethnicTable[ethnicity]) * \\\n",
    "              float(genderTable[gender][ethnicity]) * \\\n",
    "              float(nameProb[gender][name][ethnicity])\n",
    "        if bestRes <= res:\n",
    "            bestRes = res\n",
    "            theName = ethnicity\n",
    "    return theName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6452644613186043\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for index, row in theData.iterrows():\n",
    "    if predictDep(row['GNDR'],row['NM']) == row['ETHCTY']:\n",
    "        acc += 1\n",
    "print(acc / len(theData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After predicting with dependency, the accuracy did not improve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
